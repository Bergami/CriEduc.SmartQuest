"""
ðŸŽ¯ DocumentAnalysisOrchestrator - FASE 4 SOLID + Dependency Injection

Orquestrador especializado totalmente desacoplado via Dependency Injection.

FASE 4 - DEPENDENCY INJECTION APLICADO:
- Todas as dependÃªncias sÃ£o INTERFACES, nÃ£o implementaÃ§Ãµes
- Zero acoplamento entre classes
- Auto-wiring via DI Container
- FÃ¡cil substituiÃ§Ã£o de implementaÃ§Ãµes
- Testabilidade mÃ¡xima com mocks

EVOLUÃ‡ÃƒO ARQUITETURAL:
- FASE 3: ImplementaÃ§Ãµes concretas injetadas manualmente
- FASE 4: Interfaces abstratas + DI Container auto-wiring

DEPENDENCIES VIA INTERFACES:
- IImageCategorizer: CategorizaÃ§Ã£o de imagens
- IImageExtractor: ExtraÃ§Ã£o de imagens  
- IContextBuilder: ConstruÃ§Ã£o de context blocks
- IFigureProcessor: Processamento de figuras

BENEFÃCIOS ALCANÃ‡ADOS:
âœ… Zero acoplamento (DIP principle)
âœ… Auto-wiring automÃ¡tico de dependÃªncias
âœ… SubstituiÃ§Ã£o transparente de implementaÃ§Ãµes
âœ… Testes com mocks facilitados
âœ… ConfiguraÃ§Ã£o centralizada no DI Container
"""
import logging
from typing import Dict, Any, List
from uuid import uuid4
from fastapi import UploadFile

from app.parsers.header_parser import HeaderParser
from app.parsers.question_parser import QuestionParser
from app.core.interfaces import (
    IImageCategorizer,
    IImageExtractor,
    IContextBuilder,
    IFigureProcessor
)
from app.models.internal import (
    InternalDocumentResponse,
    InternalDocumentMetadata,
    InternalQuestion,
    InternalContextBlock,
    InternalImageData
)
from app.core.exceptions import DocumentProcessingError

logger = logging.getLogger(__name__)


class DocumentAnalysisOrchestrator:
    """
    ðŸŽ¯ FASE 4: Orquestrador com Dependency Injection Completo
    
    TRANSFORMAÃ‡ÃƒO ARQUITETURAL:
    - ANTES: DependÃªncias concretas injetadas manualmente
    - DEPOIS: Interfaces abstratas + auto-wiring via DI Container
    
    PRINCÃPIOS SOLID + DI:
    - SRP: Uma Ãºnica responsabilidade - orquestrar pipeline
    - OCP: ExtensÃ­vel via diferentes implementaÃ§Ãµes das interfaces
    - LSP: Qualquer implementaÃ§Ã£o das interfaces pode ser usada
    - ISP: Interfaces mÃ­nimas e especÃ­ficas por responsabilidade
    - DIP: Depende apenas de abstraÃ§Ãµes (interfaces)
    
    DEPENDENCY INJECTION:
    - Todas as dependÃªncias sÃ£o INTERFACES
    - Resolvidas automaticamente pelo DI Container
    - Zero acoplamento com implementaÃ§Ãµes concretas
    - ConfiguraÃ§Ã£o centralizada em di_config.py
    
    Pipeline de AnÃ¡lise (7 Fases):
    1. ðŸ“‹ PreparaÃ§Ã£o de contexto de anÃ¡lise
    2. ðŸ“¸ ExtraÃ§Ã£o e categorizaÃ§Ã£o de imagens
    3. ðŸ“„ Parsing de header e metadados
    4. â“ ExtraÃ§Ã£o de questÃµes dos parÃ¡grafos
    5. ðŸ§± ConstruÃ§Ã£o de context blocks refatorados
    6. ðŸ–¼ï¸ AssociaÃ§Ã£o de figuras Ã s questÃµes
    7. ðŸ“¦ AgregaÃ§Ã£o final da resposta
    """
    
    def __init__(self,
                 image_categorizer: IImageCategorizer,  # â† INTERFACE, nÃ£o implementaÃ§Ã£o
                 image_extractor: IImageExtractor,      # â† INTERFACE, nÃ£o implementaÃ§Ã£o
                 context_builder: IContextBuilder,      # â† INTERFACE, nÃ£o implementaÃ§Ã£o
                 figure_processor: IFigureProcessor):   # â† INTERFACE, nÃ£o implementaÃ§Ã£o
        """
        ðŸ”§ FASE 4: Dependency Injection com INTERFACES PURAS
        
        TRANSFORMAÃ‡ÃƒO ARQUITETURAL:
        - ANTES: DependÃªncias concretas (ImageCategorizationService, etc.)
        - DEPOIS: DependÃªncias abstratas (IImageCategorizer, etc.)
        
        BENEFÃCIOS DA MUDANÃ‡A:
        1. ZERO ACOPLAMENTO: NÃ£o conhece implementaÃ§Ãµes concretas
        2. SUBSTITUIBILIDADE: Qualquer implementaÃ§Ã£o da interface serve
        3. TESTABILIDADE: FÃ¡cil injetar mocks que implementam as interfaces
        4. CONFIGURABILIDADE: DI Container resolve automaticamente
        
        AUTO-WIRING PROCESS:
        1. DI Container inspeciona este construtor
        2. VÃª que precisa de IImageCategorizer, IImageExtractor, etc.
        3. Consulta registros: IImageCategorizer -> ImageCategorizationService
        4. Resolve recursivamente todas as dependÃªncias
        5. Instancia DocumentAnalysisOrchestrator com tudo injetado
        
        Args:
            image_categorizer: Interface para categorizaÃ§Ã£o de imagens
            image_extractor: Interface para extraÃ§Ã£o de imagens
            context_builder: Interface para construÃ§Ã£o de context blocks
            figure_processor: Interface para processamento de figuras
        """
        # Armazenar dependÃªncias (agora sÃ£o INTERFACES, nÃ£o implementaÃ§Ãµes)
        self._image_categorizer = image_categorizer
        self._image_extractor = image_extractor
        self._context_builder = context_builder
        self._figure_processor = figure_processor
        self._logger = logging.getLogger(__name__)
        
        # Log de inicializaÃ§Ã£o para debug
        self._logger.info("ðŸŽ­ DocumentAnalysisOrchestrator initialized with DI interfaces")
        self._logger.debug(f"  ðŸ“‹ Image Categorizer: {type(image_categorizer).__name__}")
        self._logger.debug(f"  ðŸ“¸ Image Extractor: {type(image_extractor).__name__}")
        self._logger.debug(f"  ðŸ§± Context Builder: {type(context_builder).__name__}")
        self._logger.debug(f"  ðŸ–¼ï¸ Figure Processor: {type(figure_processor).__name__}")

    async def orchestrate_analysis(self,
                                  extracted_data: Dict[str, Any],
                                  email: str,
                                  filename: str,
                                  file: UploadFile,
                                  use_refactored: bool = True) -> InternalDocumentResponse:
        """
        ðŸŽ¯ Orquestra todo o pipeline de anÃ¡lise de documento.
        
        Este Ã© o mÃ©todo principal que coordena todas as fases da anÃ¡lise,
        delegando para os serviÃ§os especializados.
        
        Args:
            extracted_data: Dados brutos extraÃ­dos pelo DocumentExtractionService
            email: Email do usuÃ¡rio
            filename: Nome do arquivo original
            file: Objeto UploadFile para fallback de extraÃ§Ã£o
            use_refactored: Flag para usar lÃ³gica de processamento avanÃ§ada
            
        Returns:
            InternalDocumentResponse: Resposta completa estruturada
            
        Raises:
            DocumentProcessingError: Em caso de falha no pipeline
        """
        document_id = str(uuid4())
        self._logger.info(f"ðŸŽ¯ Starting document analysis orchestration for {filename} (user: {email})")
        
        try:
            # Phase 1: PreparaÃ§Ã£o de dados bÃ¡sicos
            analysis_context = await self._prepare_analysis_context(
                extracted_data, email, filename, document_id
            )
            
            # Phase 2: ExtraÃ§Ã£o e categorizaÃ§Ã£o de imagens
            image_analysis = await self._execute_image_analysis_phase(
                file, analysis_context, document_id
            )
            
            # Phase 3: Parsing de header e metadados
            header_metadata = await self._execute_header_parsing_phase(
                analysis_context, image_analysis
            )
            
            # Phase 4: ExtraÃ§Ã£o de questÃµes
            questions_and_context = await self._execute_question_extraction_phase(
                analysis_context, image_analysis
            )
            
            # Phase 5: ConstruÃ§Ã£o de context blocks refatorados
            enhanced_context_blocks = await self._execute_context_building_phase(
                analysis_context, image_analysis, use_refactored
            )
            
            # Phase 6: AssociaÃ§Ã£o de figuras (se aplicÃ¡vel)
            enhanced_questions = await self._execute_figure_association_phase(
                analysis_context, questions_and_context["questions"]
            )
            
            # Phase 7: AgregaÃ§Ã£o final
            final_response = await self._aggregate_final_response(
                analysis_context,
                image_analysis,
                header_metadata,
                enhanced_questions,
                enhanced_context_blocks or questions_and_context["context_blocks"]
            )
            
            self._logger.info(f"âœ… Document analysis orchestration completed successfully for {filename}")
            return final_response
            
        except Exception as e:
            self._logger.error(f"âŒ Document analysis orchestration failed for {filename}: {str(e)}")
            raise DocumentProcessingError(f"Analysis pipeline failed: {str(e)}") from e

    async def _prepare_analysis_context(self,
                                      extracted_data: Dict[str, Any],
                                      email: str,
                                      filename: str,
                                      document_id: str) -> Dict[str, Any]:
        """
        Phase 1: Prepara o contexto bÃ¡sico para anÃ¡lise.
        """
        self._logger.info("ðŸ“‹ Phase 1: Preparing analysis context")
        
        extracted_text = extracted_data.get("text", "")
        azure_result = extracted_data.get("metadata", {}).get("raw_response", {})
        
        context = {
            "extracted_text": extracted_text,
            "azure_result": azure_result,
            "email": email,
            "filename": filename,
            "document_id": document_id,
            "provider_metadata": extracted_data.get("metadata", {})
        }
        
        self._logger.info(f"âœ… Phase 1 complete: Context prepared with Azure result: {bool(azure_result)}")
        return context

    async def _execute_image_analysis_phase(self,
                                          file: UploadFile,
                                          analysis_context: Dict[str, Any],
                                          document_id: str) -> Dict[str, Any]:
        """
        Phase 2: Executa extraÃ§Ã£o e categorizaÃ§Ã£o de imagens.
        """
        self._logger.info("ðŸ–¼ï¸ Phase 2: Executing image analysis (extraction + categorization)")
        
        # 2.1: ExtraÃ§Ã£o com fallback usando orquestrador especializado
        image_data = await self._image_extractor.extract_with_fallback(
            file=file,
            document_analysis_result=analysis_context["azure_result"],
            document_id=f"{analysis_context['email']}_{analysis_context['filename']}"
        )
        
        if image_data:
            self._logger.info(f"ðŸ–¼ï¸ Phase 2.1: {len(image_data)} images extracted successfully")
        else:
            self._logger.warning("âš ï¸ Phase 2.1: No images extracted")
            image_data = {}

        # 2.2: CategorizaÃ§Ã£o usando interface (DIP aplicado)
        header_images_pydantic, content_images_pydantic = [], []
        
        if isinstance(image_data, dict) and image_data:
            self._logger.info(f"ðŸ·ï¸ Phase 2.2: Categorizing {len(image_data)} images using Pydantic interface")
            
            header_images_pydantic, content_images_pydantic = self._image_categorizer.categorize_extracted_images(
                image_data, 
                analysis_context["azure_result"], 
                document_id=f"analyze_{len(image_data)}_images"
            )
            
            self._logger.info(f"âœ… Phase 2.2: Categorization complete - {len(header_images_pydantic)} header, {len(content_images_pydantic)} content")
        else:
            self._logger.info("â„¹ï¸ Phase 2.2: Skipping categorization - no valid image data")

        all_categorized_images = header_images_pydantic + content_images_pydantic
        
        result = {
            "image_data": image_data,
            "header_images": header_images_pydantic,
            "content_images": content_images_pydantic,
            "all_images": all_categorized_images
        }
        
        self._logger.info("âœ… Phase 2 complete: Image analysis finished")
        return result

    async def _execute_header_parsing_phase(self,
                                          analysis_context: Dict[str, Any],
                                          image_analysis: Dict[str, Any]) -> InternalDocumentMetadata:
        """
        Phase 3: Executa parsing do header e metadados.
        """
        self._logger.info("ðŸ“„ Phase 3: Executing header parsing")
        
        header_metadata = HeaderParser.parse_to_pydantic(
            header=analysis_context["extracted_text"],
            header_images=image_analysis["header_images"],
            content_images=image_analysis["content_images"]
        )
        
        self._logger.info("âœ… Phase 3 complete: Header metadata parsed")
        return header_metadata

    async def _execute_question_extraction_phase(self,
                                               analysis_context: Dict[str, Any],
                                               image_analysis: Dict[str, Any]) -> Dict[str, List]:
        """
        Phase 4: Executa extraÃ§Ã£o de questÃµes dos parÃ¡grafos Azure.
        """
        self._logger.info("â“ Phase 4: Executing question extraction")
        
        azure_result = analysis_context["azure_result"]
        image_data = image_analysis["image_data"]
        
        # Extrair parÃ¡grafos Azure
        azure_paragraphs = azure_result.get("paragraphs", []) if azure_result else []
        
        questions = []
        context_blocks = []
        
        if azure_paragraphs:
            self._logger.info(f"ðŸ“ Phase 4.1: Processing {len(azure_paragraphs)} Azure paragraphs")
            
            # Preparar parÃ¡grafos no formato esperado
            paragraph_list = [{"content": p.get("content", "")} for p in azure_paragraphs if p.get("content")]
            
            # Extrair usando mÃ©todo eficiente
            raw_data = QuestionParser.extract_from_paragraphs(paragraph_list, image_data)
            
            # Converter para Pydantic com validaÃ§Ã£o
            for i, q in enumerate(raw_data.get("questions", [])):
                try:
                    if not q.get("question"):
                        self._logger.warning(f"âš ï¸ Question {i+1} has empty content, skipping")
                        continue
                        
                    pydantic_q = InternalQuestion.from_legacy_question(q)
                    questions.append(pydantic_q)
                    self._logger.debug(f"âœ… Question {i+1} converted: {len(pydantic_q.content.statement)} chars")
                except Exception as e:
                    self._logger.error(f"âŒ Error converting question {i+1}: {e}")
                    continue
            
            for i, cb in enumerate(raw_data.get("context_blocks", [])):
                try:
                    pydantic_cb = InternalContextBlock.from_legacy_context_block(cb)
                    context_blocks.append(pydantic_cb)
                except Exception as e:
                    self._logger.warning(f"âš ï¸ Error converting context block {i+1}: {e}")
                    continue
            
            self._logger.info(f"âœ… Phase 4: Extracted {len(questions)} questions, {len(context_blocks)} context blocks")
        else:
            self._logger.error("âŒ Phase 4: No Azure paragraphs available - cannot extract questions")
            raise ValueError("Azure paragraphs are required for SOLID extraction")
        
        return {
            "questions": questions,
            "context_blocks": context_blocks
        }

    async def _execute_context_building_phase(self,
                                            analysis_context: Dict[str, Any],
                                            image_analysis: Dict[str, Any],
                                            use_refactored: bool) -> List[InternalContextBlock]:
        """
        Phase 5: Executa construÃ§Ã£o de context blocks refatorados.
        """
        if not use_refactored:
            self._logger.info("â„¹ï¸ Phase 5: Skipped - refactored context building disabled")
            return None
            
        self._logger.info("ðŸ”§ Phase 5: Executing refactored context building")
        
        azure_result = analysis_context["azure_result"]
        image_data = image_analysis["image_data"]
        
        if not azure_result:
            self._logger.warning("âš ï¸ Phase 5: No Azure result - skipping enhanced context building")
            return None
        
        try:
            self._logger.info("ðŸ”¥ Phase 5.1: Using parse_to_pydantic() - Native Pydantic Interface")
            
            enhanced_context_blocks = self._context_builder.parse_to_pydantic(azure_result, image_data)
            
            blocks_with_images = sum(1 for cb in enhanced_context_blocks if cb.has_images)
            self._logger.info(f"âœ… Phase 5: Created {len(enhanced_context_blocks)} context blocks ({blocks_with_images} with images)")
            
            return enhanced_context_blocks
            
        except Exception as e:
            self._logger.warning(f"ðŸ”„ Phase 5: parse_to_pydantic failed ({e}), using legacy method")
            
            enhanced_context_blocks_dict = self._context_builder.build_context_blocks_from_azure_figures(
                azure_result, image_data
            )
            
            if enhanced_context_blocks_dict:
                context_blocks = [
                    InternalContextBlock.from_legacy_context_block(cb) 
                    for cb in enhanced_context_blocks_dict
                ]
                self._logger.info(f"âœ… Phase 5: Created {len(context_blocks)} context blocks (legacy method)")
                return context_blocks
            else:
                self._logger.warning("âš ï¸ Phase 5: No enhanced context blocks created")
                return None

    async def _execute_figure_association_phase(self,
                                              analysis_context: Dict[str, Any],
                                              questions: List[InternalQuestion]) -> List[InternalQuestion]:
        """
        Phase 6: Executa associaÃ§Ã£o de figuras Ã s questÃµes.
        """
        self._logger.info("ðŸ–¼ï¸ Phase 6: Executing figure association")
        
        try:
            # ðŸ”§ FASE 4: Usar interface ao invÃ©s de chamada estÃ¡tica
            # ANTES: AzureFigureProcessor.process_figures_from_azure_response(azure_result)
            # DEPOIS: self._figure_processor.process_figures(images, context_blocks)
            
            images = analysis_context.get("categorized_images", [])
            context_blocks = analysis_context.get("context_blocks", [])
            
            # Processar figuras atravÃ©s da interface
            figure_results = await self._figure_processor.process_figures(images, context_blocks)
            
            # Extrair questÃµes melhoradas dos resultados
            enhanced_questions = figure_results.get("enhanced_questions", questions)
            
            self._logger.info("âœ… Phase 6: Questions enhanced with figure associations")
            return enhanced_questions
            
        except Exception as e:
            self._logger.warning(f"ðŸ”„ Phase 6: Figure association failed: {e}, proceeding without enhancement")
            return questions

    async def _aggregate_final_response(self,
                                      analysis_context: Dict[str, Any],
                                      image_analysis: Dict[str, Any],
                                      header_metadata: InternalDocumentMetadata,
                                      questions: List[InternalQuestion],
                                      context_blocks: List[InternalContextBlock]) -> InternalDocumentResponse:
        """
        Phase 7: Agrega todos os resultados na resposta final.
        """
        self._logger.info("ðŸ“¦ Phase 7: Aggregating final response")
        
        response = InternalDocumentResponse(
            email=analysis_context["email"],
            document_id=analysis_context["document_id"],
            filename=analysis_context["filename"],
            document_metadata=header_metadata,
            questions=questions,
            context_blocks=context_blocks,
            extracted_text=analysis_context["extracted_text"],
            provider_metadata=analysis_context["provider_metadata"],
            all_images=image_analysis["all_images"]
        )
        
        self._logger.info(f"âœ… Phase 7 complete: Final response aggregated with {len(questions)} questions, {len(context_blocks)} context blocks")
        return response