ğŸ” 1. DuplicaÃ§Ã£o de CÃ³digo
1.1 LÃ³gica de Hash Duplicada
LocalizaÃ§Ã£o: app/models/persistence/question.py e app/services/persistence/question_service.py

Problema:
A lÃ³gica de geraÃ§Ã£o de hash aparece em dois lugares:

# Em question.py (mÃ©todo de modelo)

def generate_content_hash(self) -> str:
content = {
"text": self.text,
"alternatives": sorted([
{"text": alt.text, "is_correct": alt.is_correct}
for alt in self.alternatives
], key=lambda x: x["text"])
}
content_str = json.dumps(content, sort_keys=True, ensure_ascii=False)
return hashlib.sha256(content_str.encode('utf-8')).hexdigest()

# Em question_service.py (mÃ©todo estÃ¡tico)

@staticmethod
def \_generate_content_hash(question_data: dict) -> str:
content = {
"text": question_data.get("text", ""),
"alternatives": sorted([
{"text": alt.get("text", ""), "is_correct": alt.get("is_correct", False)}
for alt in question_data.get("alternatives", [])
], key=lambda x: x["text"])
}
content_str = json.dumps(content, sort_keys=True, ensure_ascii=False)
return hashlib.sha256(content_str.encode('utf-8')).hexdigest()

Impacto: DuplicaÃ§Ã£o de lÃ³gica dificulta manutenÃ§Ã£o e pode levar a inconsistÃªncias.

SugestÃ£o:
Centralizar em um Ãºnico local, preferencialmente no modelo:

# Em question.py

@staticmethod
def calculate_content_hash(text: str, alternatives: List[dict]) -> str:
"""Calculate content hash for deduplication."""
content = {
"text": text,
"alternatives": sorted([
{"text": alt["text"], "is_correct": alt["is_correct"]}
for alt in alternatives
], key=lambda x: x["text"])
}
content_str = json.dumps(content, sort_keys=True, ensure_ascii=False)
return hashlib.sha256(content_str.encode('utf-8')).hexdigest()

def generate_content_hash(self) -> str:
"""Generate hash from current instance data."""
alternatives_data = [
{"text": alt.text, "is_correct": alt.is_correct}
for alt in self.alternatives
]
return self.calculate_content_hash(self.text, alternatives_data)

1.2 Tratamento de ExceÃ§Ãµes Repetido
LocalizaÃ§Ã£o: app/services/persistence/question_service.py

Problema:
PadrÃ£o de tratamento de exceÃ§Ã£o repetido em mÃºltiplos mÃ©todos:

except Exception as e:
self.logger.error(f"Error in method_name: {str(e)}")
raise

SugestÃ£o:
Criar um decorator para tratamento padronizado:

from functools import wraps
from typing import Callable, Any

def handle_service_errors(operation_name: str) -> Callable:
"""Decorator for standardized error handling in service methods."""
def decorator(func: Callable) -> Callable:
@wraps(func)
async def wrapper(self, *args, \*\*kwargs) -> Any:
try:
return await func(self, *args, \*\*kwargs)
except Exception as e:
self.logger.error(f"Error in {operation_name}: {str(e)}")
raise
return wrapper
return decorator

# Uso:

@handle_service_errors("save_question")
async def save_question(self, question: Question, request_id: str) -> Question: # implementaÃ§Ã£o

ğŸ§± 2. Responsabilidade Ãšnica (SRP)
2.1 QuestionService Acumula MÃºltiplas Responsabilidades
LocalizaÃ§Ã£o: app/services/persistence/question_service.py

Problema:
O QuestionService estÃ¡ responsÃ¡vel por:

PersistÃªncia de questÃµes
DetecÃ§Ã£o de duplicatas
GeraÃ§Ã£o de hashes
ValidaÃ§Ã£o de dados
Logging detalhado
SugestÃ£o:
Separar em classes especializadas:

# app/services/persistence/deduplication_service.py

class QuestionDeduplicationService:
"""Service specialized in question deduplication."""

    def __init__(self, repository: IQuestionRepository):
        self.repository = repository

    async def check_duplicate(
        self,
        content_hash: str,
        exam_id: str
    ) -> Optional[Question]:
        """Check if question is duplicate."""
        return await self.repository.find_by_content_hash(
            content_hash,
            exam_id
        )

    async def find_similar_questions(
        self,
        content_hash: str,
        limit: int = 5
    ) -> List[Question]:
        """Find similar questions across all exams."""
        return await self.repository.find_similar_by_hash(
            content_hash,
            limit
        )

# app/services/persistence/question_service.py

class QuestionService:
"""Service for question persistence operations."""

    def __init__(
        self,
        repository: IQuestionRepository,
        deduplication_service: QuestionDeduplicationService,
        logger: Logger
    ):
        self.repository = repository
        self.deduplication = deduplication_service
        self.logger = logger

    async def save_question(
        self,
        question: Question,
        request_id: str
    ) -> Question:
        """Save question with deduplication check."""
        # Simplified logic focusing on persistence
        duplicate = await self.deduplication.check_duplicate(
            question.content_hash,
            question.exam_id
        )

        if duplicate:
            self.logger.info(f"Duplicate found: {duplicate.id}")
            return duplicate

        return await self.repository.save(question)

2.2 QuestionProcessor Mistura OrquestraÃ§Ã£o e LÃ³gica de NegÃ³cio
LocalizaÃ§Ã£o: app/services/core/question_processor.py

Problema:
O mÃ©todo process_questions estÃ¡ muito extenso e mistura:

OrquestraÃ§Ã£o de fluxo
TransformaÃ§Ã£o de dados
Logging detalhado
Tratamento de erros
SugestÃ£o:
Extrair mÃ©todos privados para responsabilidades especÃ­ficas:

class QuestionProcessor:
async def process_questions(
self,
extracted_questions: List[ExtractedQuestion],
exam_id: str,
request_id: str
) -> ProcessedQuestionsResponse:
"""Process and save questions with deduplication."""
self.\_log_processing_start(len(extracted_questions), exam_id, request_id)

        results = await self._process_all_questions(
            extracted_questions,
            exam_id,
            request_id
        )

        stats = self._calculate_statistics(results)
        self._log_processing_summary(stats, request_id)

        return self._build_response(results, stats)

    async def _process_all_questions(
        self,
        extracted_questions: List[ExtractedQuestion],
        exam_id: str,
        request_id: str
    ) -> List[ProcessingResult]:
        """Process all questions and collect results."""
        results = []
        for idx, extracted in enumerate(extracted_questions, 1):
            result = await self._process_single_question(
                extracted,
                exam_id,
                request_id,
                idx
            )
            results.append(result)
        return results

    def _calculate_statistics(
        self,
        results: List[ProcessingResult]
    ) -> Dict[str, int]:
        """Calculate processing statistics."""
        return {
            "total": len(results),
            "saved": sum(1 for r in results if r.status == "saved"),
            "duplicates": sum(1 for r in results if r.status == "duplicate"),
            "failed": sum(1 for r in results if r.status == "failed")
        }

3.  CÃ³digo Morto ou DesnecessÃ¡rio
    3.1 Imports NÃ£o Utilizados
    LocalizaÃ§Ã£o: test_deduplication.py

Problema:

import sys
import os

# sys e os nÃ£o sÃ£o utilizados no cÃ³digo

SugestÃ£o:
Remover imports nÃ£o utilizados.

3.2 VariÃ¡veis NÃ£o Utilizadas
LocalizaÃ§Ã£o: app/services/persistence/question_service.py

Problema:

async def save_question(self, question: Question, request_id: str) -> Question: # request_id Ã© logado mas nÃ£o usado para rastreamento real

SugestÃ£o:
Se request_id nÃ£o Ã© usado para correlaÃ§Ã£o, considerar removÃª-lo ou implementar uso consistente para rastreamento distribuÃ­do.

3.3 CÃ³digo Comentado
LocalizaÃ§Ã£o: MÃºltiplos arquivos

Problema:
PresenÃ§a de cÃ³digo comentado que deveria estar no histÃ³rico do Git:

# Old implementation removed

# def old_method():

# pass

SugestÃ£o:
Remover cÃ³digo comentado e confiar no controle de versÃ£o.

ğŸ’¬ 4. ComentÃ¡rios
4.1 ComentÃ¡rios Redundantes
LocalizaÃ§Ã£o: app/services/persistence/question_service.py

Problema:

# Check for duplicates

duplicate = await self.\_check_duplicate(...)

# Save question

saved = await self.repository.save(question)

SugestÃ£o:
Remover comentÃ¡rios Ã³bvios. O cÃ³digo deve ser autoexplicativo:

duplicate = await self.\_check_duplicate(...)
if duplicate:
return duplicate

return await self.repository.save(question)

4.2 Docstrings Incompletas
LocalizaÃ§Ã£o: MÃºltiplos mÃ©todos

Problema:
Faltam docstrings em vÃ¡rios mÃ©todos ou estÃ£o incompletas:

def \_generate_content_hash(question_data: dict) -> str: # Sem docstring explicando formato esperado de question_data

SugestÃ£o:
Adicionar docstrings completas conforme PEP 257:  
def \_generate_content_hash(question_data: dict) -> str:
"""Generate SHA-256 hash from question content.

    Args:
        question_data: Dictionary containing:
            - text (str): Question text
            - alternatives (List[dict]): List of alternatives with 'text' and 'is_correct'

    Returns:
        str: 64-character hexadecimal SHA-256 hash

    Example:
        >>> data = {
        ...     "text": "What is 2+2?",
        ...     "alternatives": [
        ...         {"text": "4", "is_correct": True},
        ...         {"text": "5", "is_correct": False}
        ...     ]
        ... }
        >>> hash_value = _generate_content_hash(data)
        >>> len(hash_value)
        64
    """

4.3 ComentÃ¡rios Desatualizados
LocalizaÃ§Ã£o: app/models/persistence/question.py

Problema:
ComentÃ¡rios que nÃ£o refletem o estado atual do cÃ³digo apÃ³s refatoraÃ§Ãµes.

SugestÃ£o:
Revisar e atualizar ou remover comentÃ¡rios desatualizados durante refatoraÃ§Ãµes.

ğŸ§ª 5. Testabilidade
5.1 Testes Focados Apenas em Caminho Feliz
LocalizaÃ§Ã£o: tests/unit/services/persistence/test_question_service.py

Problema:
Testes existentes cobrem principalmente cenÃ¡rios de sucesso:

async def test_save_question_success(self): # Apenas testa o caso de sucesso

ugestÃ£o:
Adicionar testes para casos de borda e falhas:
class TestQuestionServiceEdgeCases:
"""Test edge cases and failure scenarios."""

    async def test_save_question_with_empty_text(self):
        """Test saving question with empty text."""
        question = Question(text="", alternatives=[], exam_id="exam1")
        with pytest.raises(ValidationError):
            await service.save_question(question, "req-1")

    async def test_save_question_with_no_alternatives(self):
        """Test saving question without alternatives."""
        question = Question(text="Question?", alternatives=[], exam_id="exam1")
        with pytest.raises(ValidationError):
            await service.save_question(question, "req-1")

    async def test_save_question_with_all_incorrect_alternatives(self):
        """Test question with no correct alternative."""
        question = Question(
            text="Question?",
            alternatives=[
                Alternative(text="A", is_correct=False),
                Alternative(text="B", is_correct=False)
            ],
            exam_id="exam1"
        )
        with pytest.raises(ValidationError):
            await service.save_question(question, "req-1")

    async def test_save_question_database_connection_failure(self):
        """Test handling of database connection errors."""
        mock_repo.save.side_effect = ConnectionError("DB unavailable")
        question = create_valid_question()

        with pytest.raises(ConnectionError):
            await service.save_question(question, "req-1")

    async def test_duplicate_check_with_hash_collision(self):
        """Test behavior with hash collision (rare but possible)."""
        # Simulate hash collision scenario
        pass

    async def test_save_question_with_duplicate_alternatives(self):
        """Test question with duplicate alternative texts."""
        question = Question(
            text="Question?",
            alternatives=[
                Alternative(text="Same", is_correct=True),
                Alternative(text="Same", is_correct=False)
            ],
            exam_id="exam1"
        )
        # Should this be allowed or rejected?
        result = await service.save_question(question, "req-1")
        # Add assertions

    async def test_concurrent_duplicate_saves(self):
        """Test race condition when saving duplicates concurrently."""
        import asyncio
        question = create_valid_question()

        results = await asyncio.gather(
            service.save_question(question, "req-1"),
            service.save_question(question, "req-2"),
            service.save_question(question, "req-3")
        )

        # All should return the same question (only one saved)
        assert len(set(r.id for r in results)) == 1

5.2 DependÃªncias DifÃ­ceis de Mockar
LocalizaÃ§Ã£o: app/services/core/question_processor.py

Problema:
DependÃªncias diretas dificultam testes isolados:

class QuestionProcessor:
def **init**(self, question_service: QuestionService, logger: Logger):
self.question_service = question_service
self.logger = logger

SugestÃ£o:
Usar injeÃ§Ã£o de dependÃªncia via interfaces:

class QuestionProcessor:
def **init**(
self,
question_service: IQuestionService, # Interface em vez de implementaÃ§Ã£o
logger: ILogger
):
self.question_service = question_service
self.logger = logger

5.3 Falta de Testes de IntegraÃ§Ã£o
Problema:
NÃ£o hÃ¡ testes que validem o fluxo completo de detecÃ§Ã£o de duplicatas com MongoDB real.

SugestÃ£o:
Adicionar testes de integraÃ§Ã£o:

# tests/integration/test_deduplication_flow.py

import pytest
from motor.motor_asyncio import AsyncIOMotorClient
from testcontainers.mongodb import MongoDbContainer

@pytest.mark.integration
class TestDeduplicationIntegration:
"""Integration tests for deduplication with real MongoDB."""

    @pytest.fixture(scope="class")
    async def mongodb_container(self):
        """Start MongoDB container for testing."""
        with MongoDbContainer("mongo:7.0") as mongo:
            yield mongo

    @pytest.fixture
    async def db_client(self, mongodb_container):
        """Create MongoDB client."""
        client = AsyncIOMotorClient(mongodb_container.get_connection_url())
        yield client
        await client.drop_database("test_db")
        client.close()

    async def test_duplicate_detection_with_real_db(self, db_client):
        """Test duplicate detection with real MongoDB instance."""
        repository = MongoQuestionRepository(db_client, "test_db")
        service = QuestionService(repository, logger)

        question1 = create_question("What is 2+2?")
        question2 = create_question("What is 2+2?")  # Duplicate

        saved1 = await service.save_question(question1, "req-1")
        saved2 = await service.save_question(question2, "req-2")

        assert saved1.id == saved2.id

        # Verify only one document in database
        count = await repository.count_by_exam(question1.exam_id)
        assert count == 1

5.4 Cobertura de Testes Insuficiente
Ãreas CrÃ­ticas Sem Testes:

question_extraction_service.py - Sem testes unitÃ¡rios
CenÃ¡rios de erro na camada de controller
ValidaÃ§Ã£o de hash em casos extremos
Performance com grandes volumes de dados
SugestÃ£o:
Estabelecer meta de cobertura mÃ­nima de 80% e adicionar testes para Ã¡reas crÃ­ticas.

ğŸ§  6. Clareza e Legibilidade
6.1 Nomes de VariÃ¡veis Pouco Descritivos
LocalizaÃ§Ã£o: app/services/persistence/question_service.py

Problema:
async def save_question(self, question: Question, request_id: str) -> Question:
h = question.content_hash # 'h' nÃ£o Ã© descritivo
dup = await self.\_check_duplicate(h, question.exam_id) # 'dup' abreviado

SugestÃ£o:
async def save_question(self, question: Question, request_id: str) -> Question:
content_hash = question.content_hash
existing_question = await self.\_check_duplicate(content_hash, question.exam_id)

    if existing_question:
        self.logger.info(
            f"Duplicate question found. "
            f"Original ID: {existing_question.id}, "
            f"Request: {request_id}"
        )
        return existing_question

6.2 MÃ©todos Longos com MÃºltiplas Responsabilidades
LocalizaÃ§Ã£o: app/services/core/question_processor.py

Problema:
MÃ©todo process_questions com mais de 50 linhas, difÃ­cil de entender de relance.

SugestÃ£o:
JÃ¡ abordado na seÃ§Ã£o SRP - quebrar em mÃ©todos menores e mais focados.

6.3 Magic Numbers
LocalizaÃ§Ã£o: app/services/persistence/question_service.py

Problema:

similar = await self.repository.find_similar_by_hash(content_hash, 5)

SugestÃ£o:

DEFAULT_SIMILAR_QUESTIONS_LIMIT = 5

similar = await self.repository.find_similar_by_hash(
content_hash,
limit=DEFAULT_SIMILAR_QUESTIONS_LIMIT
)

ğŸ“ 7. Arquitetura e Design
7.1 ViolaÃ§Ã£o do PrincÃ­pio de InversÃ£o de DependÃªncia
LocalizaÃ§Ã£o: app/services/core/question_processor.py

Problema:
DependÃªncia direta de implementaÃ§Ã£o concreta:

from app.services.persistence.question_service import QuestionService

class QuestionProcessor:
def **init**(self, question_service: QuestionService, ...):

SugestÃ£o:
Depender de abstraÃ§Ãµes:

7.2 Acoplamento Entre Camadas
Problema:
A camada de serviÃ§o estÃ¡ fortemente acoplada ao modelo de persistÃªncia.

SugestÃ£o:
Introduzir DTOs para transferÃªncia entre camadas:

# app/dtos/persistence/question_dto.py

from dataclasses import dataclass
from typing import List

@dataclass
class QuestionDTO:
"""Data transfer object for question data."""
text: str
alternatives: List[AlternativeDTO]
exam_id: str
content_hash: Optional[str] = None

    def to_domain_model(self) -> Question:
        """Convert DTO to domain model."""
        return Question(
            text=self.text,
            alternatives=[alt.to_domain_model() for alt in self.alternatives],
            exam_id=self.exam_id,
            content_hash=self.content_hash
        )

7.3 Falta de PadrÃ£o Repository Completo
Problema:
O repository nÃ£o implementa todos os mÃ©todos esperados de um padrÃ£o Repository completo.

SugestÃ£o:
Definir interface completa:

# app/core/interfaces.py

from abc import ABC, abstractmethod
from typing import List, Optional

class IQuestionRepository(ABC):
"""Repository interface for question persistence."""

    @abstractmethod
    async def save(self, question: Question) -> Question:
        """Save or update a question."""
        pass

    @abstractmethod
    async def find_by_id(self, question_id: str) -> Optional[Question]:
        """Find question by ID."""
        pass

    @abstractmethod
    async def find_by_exam(self, exam_id: str) -> List[Question]:
        """Find all questions for an exam."""
        pass

    @abstractmethod
    async def find_by_content_hash(
        self,
        content_hash: str,
        exam_id: str
    ) -> Optional[Question]:
        """Find question by content hash within an exam."""
        pass

    @abstractmethod
    async def delete(self, question_id: str) -> bool:
        """Delete a question."""
        pass

    @abstractmethod
    async def exists(self, question_id: str) -> bool:
        """Check if question exists."""
        pass

    @abstractmethod
    async def count_by_exam(self, exam_id: str) -> int:
        """Count questions in an exam."""
        pass

7.4 AusÃªncia de PadrÃ£o Unit of Work
Problema:
NÃ£o hÃ¡ controle transacional quando mÃºltiplas operaÃ§Ãµes precisam ser atÃ´micas.

SugestÃ£o:
Considerar implementar Unit of Work para operaÃ§Ãµes que envolvem mÃºltiplas entidades:

# app/core/unit_of_work.py

from abc import ABC, abstractmethod
from typing import AsyncContextManager

class IUnitOfWork(ABC, AsyncContextManager):
"""Unit of Work pattern for transactional operations."""

    questions: IQuestionRepository
    exams: IExamRepository

    @abstractmethod
    async def commit(self) -> None:
        """Commit all changes."""
        pass

    @abstractmethod
    async def rollback(self) -> None:
        """Rollback all changes."""
        pass

# Uso:

async with unit_of_work:
question = await unit_of_work.questions.save(question_data)
await unit_of_work.exams.update_question_count(exam_id)
await unit_of_work.commit()

ğŸ“ 8. Conformidade com PEP 8 e PEP 257
8.1 Linhas Muito Longas
LocalizaÃ§Ã£o: MÃºltiplos arquivos

Problema:  
self.logger.info(f"Processing {len(extracted_questions)} questions for exam {exam_id} (Request: {request_id})")

SugestÃ£o:
Quebrar linhas conforme PEP 8 (limite de 88-100 caracteres com Black):
self.logger.info(
f"Processing {len(extracted_questions)} questions "
f"for exam {exam_id} (Request: {request_id})"
)

8.2 Imports NÃ£o Ordenados
LocalizaÃ§Ã£o: MÃºltiplos arquivos

Problema:
Imports nÃ£o seguem a ordem padrÃ£o (stdlib, third-party, local).

SugestÃ£o:
Usar ferramenta como isort:

# Standard library

import hashlib
import json
from typing import List, Optional

# Third-party

from motor.motor_asyncio import AsyncIOMotorCollection

# Local

from app.models.persistence.question import Question
from app.core.interfaces import IQuestionRepository

8.3 Docstrings NÃ£o Conformes com PEP 257
Problema:
InconsistÃªncia no formato de docstrings.

SugestÃ£o:
Padronizar usando Google ou NumPy style:

def generate_content_hash(self) -> str:
"""Generate SHA-256 hash from question content.

    The hash is calculated from the question text and alternatives,
    ensuring consistent ordering for deduplication purposes.

    Returns:
        A 64-character hexadecimal string representing the SHA-256 hash.

    Example:
        >>> question = Question(text="What is 2+2?", ...)
        >>> hash_value = question.generate_content_hash()
        >>> len(hash_value)
        64
    """

8.4 EspaÃ§amento Inconsistente
Problema:
EspaÃ§amento inconsistente ao redor de operadores e apÃ³s vÃ­rgulas.

SugestÃ£o:
Usar formatador automÃ¡tico como Black:

pip install black
black app/ tests/

ğŸ§© 9. Complexidade CiclomÃ¡tica
9.1 MÃ©todo com Alta Complexidade
LocalizaÃ§Ã£o: app/services/core/question_processor.py::process_questions

Problema:
Complexidade ciclomÃ¡tica estimada > 15 devido a mÃºltiplos caminhos de decisÃ£o.

AnÃ¡lise:

async def process_questions(...): # 1. Loop principal
for idx, extracted in enumerate(extracted_questions, 1):
try: # 2. ConversÃ£o
question = ...

            # 3. VerificaÃ§Ã£o de duplicata
            if not question.content_hash:
                # 4. GeraÃ§Ã£o de hash
                question.content_hash = ...

            # 5. Salvamento
            saved = await self.question_service.save_question(...)

            # 6. VerificaÃ§Ã£o de duplicata apÃ³s salvar
            if saved.id != question.id:
                # LÃ³gica duplicata
            else:
                # LÃ³gica nova questÃ£o

            # 7. Tratamento de sucesso
            results.append(...)

        except Exception as e:
            # 8. Tratamento de erro
            results.append(...)

    # 9-12. CÃ¡lculo de estatÃ­sticas com mÃºltiplas condiÃ§Ãµes
    # 13-15. Logging condicional
    # 16. ConstruÃ§Ã£o de resposta

    SugestÃ£o:

Refatorar usando mÃ©todos auxiliares (jÃ¡ sugerido na seÃ§Ã£o SRP):

async def process_questions(
self,
extracted_questions: List[ExtractedQuestion],
exam_id: str,
request_id: str
) -> ProcessedQuestionsResponse:
"""Process questions with reduced complexity."""
self.\_log_processing_start(len(extracted_questions), exam_id, request_id)

    # Complexidade reduzida delegando para mÃ©todos especializados
    results = []
    for idx, extracted in enumerate(extracted_questions, 1):
        result = await self._process_single_question(
            extracted,
            exam_id,
            request_id,
            idx
        )
        results.append(result)

    return self._build_final_response(results, request_id)

async def \_process_single_question(
self,
extracted: ExtractedQuestion,
exam_id: str,
request_id: str,
index: int
) -> ProcessingResult:
"""Process a single question (complexity ~5)."""
try:
question = self.\_convert_to_domain_model(extracted, exam_id)
saved = await self.\_save_with_deduplication(question, request_id)
return self.\_create_success_result(saved, question, index)
except Exception as e:
return self.\_create_error_result(e, index)

9.2 Condicionais Aninhadas
LocalizaÃ§Ã£o: app/services/persistence/question_service.py

Problema:

if duplicate:
if duplicate.id != question.id:
if duplicate.exam_id == question.exam_id: # LÃ³gica aninhada

SugestÃ£o:
Usar retorno antecipado (early return):  
if not duplicate:
return await self.repository.save(question)

if duplicate.id == question.id:
return question

if duplicate.exam_id != question.exam_id:
raise ValueError("Hash collision across exams")

self.logger.info(f"Duplicate found: {duplicate.id}")
return duplicate

9.3 ExpressÃµes Booleanas Complexas
Problema:

if (question.content_hash and
len(question.alternatives) > 0 and
any(alt.is_correct for alt in question.alternatives) and
question.text.strip() != ""):

SugestÃ£o:
Extrair para mÃ©todo com nome descritivo:

def \_is_valid_question(self, question: Question) -> bool:
"""Check if question is valid for persistence."""
has_content_hash = bool(question.content_hash)
has_alternatives = len(question.alternatives) > 0
has_correct_answer = any(alt.is_correct for alt in question.alternatives)
has_text = question.text.strip() != ""

    return all([
        has_content_hash,
        has_alternatives,
        has_correct_answer,
        has_text
    ])

# Uso:

if not self.\_is_valid_question(question):
raise ValidationError("Invalid question data")

ğŸ¯ 11. Performance e OtimizaÃ§Ã£o
11.1 N+1 Query Problem
LocalizaÃ§Ã£o: app/services/core/question_processor.py

Problema:
Busca de duplicatas Ã© feita uma por vez dentro do loop:

for extracted in extracted_questions: # Cada iteraÃ§Ã£o faz uma query ao banco
saved = await self.question_service.save_question(question, request_id)

SugestÃ£o:
Implementar busca em lote:

async def process_questions_batch(
self,
extracted_questions: List[ExtractedQuestion],
exam_id: str,
request_id: str
) -> ProcessedQuestionsResponse:
"""Process questions with batch duplicate checking."""

    # Converter todas as questÃµes
    questions = [
        self._convert_to_domain_model(eq, exam_id)
        for eq in extracted_questions
    ]

    # Buscar todas as duplicatas de uma vez
    hashes = [q.content_hash for q in questions]
    existing_questions = await self.question_service.find_by_hashes_batch(
        hashes,
        exam_id
    )

    # Mapear duplicatas
    existing_map = {q.content_hash: q for q in existing_questions}

    # Processar com base no mapa
    results = []
    for question in questions:
        if question.content_hash in existing_map:
            results.append(self._create_duplicate_result(
                existing_map[question.content_hash]
            ))
        else:
            saved = await self.question_service.save_question(
                question,
                request_id
            )
            results.append(self._create_success_result(saved))

    return self._build_response(results)

11.2 Falta de Ãndices no Banco
Problema:
Busca por content_hash pode ser lenta sem Ã­ndice apropriado.

SugestÃ£o:
Garantir Ã­ndices no MongoDB:

# scripts/migrations/add_content_hash_index.py

async def create_indexes():
"""Create indexes for question deduplication."""
await questions_collection.create_index(
[("content_hash", 1), ("exam_id", 1)],
unique=True,
name="idx_content_hash_exam"
)

    await questions_collection.create_index(
        [("exam_id", 1)],
        name="idx_exam_id"
    )

11.3 GeraÃ§Ã£o de Hash Repetida
Problema:
Hash pode ser gerado mÃºltiplas vezes para a mesma questÃ£o.

SugestÃ£o:
Cachear hash apÃ³s primeira geraÃ§Ã£o:

class Question:
def **init**(self, ...):
self.\_content_hash: Optional[str] = None

    @property
    def content_hash(self) -> str:
        """Get content hash, generating if needed."""
        if self._content_hash is None:
            self._content_hash = self.generate_content_hash()
        return self._content_hash

    @content_hash.setter
    def content_hash(self, value: str):
        """Set content hash explicitly."""
        self._content_hash = value

ğŸ“Š MÃ©tricas de CÃ³digo
EstatÃ­sticas Estimadas
MÃ©trica Valor Atual Recomendado Status
Cobertura de Testes ~40% >80% âŒ
Complexidade CiclomÃ¡tica MÃ©dia ~12 <10 âš ï¸
DuplicaÃ§Ã£o de CÃ³digo ~8% <5% âš ï¸
Linhas por MÃ©todo (mÃ©dia) ~25 <20 âš ï¸
Conformidade PEP 8 ~75% >95% âš ï¸
Docstring Coverage ~60% >90% âŒ
ğŸ¯ PriorizaÃ§Ã£o de RefatoraÃ§Ãµes
Alta Prioridade (CrÃ­tico)
Adicionar testes para casos de erro e borda - Fundamental para confiabilidade
Implementar validaÃ§Ã£o de entrada robusta - Previne erros e vulnerabilidades
Corrigir duplicaÃ§Ã£o de lÃ³gica de hash - Evita inconsistÃªncias
Adicionar Ã­ndices no MongoDB - Performance crÃ­tica
MÃ©dia Prioridade (Importante)
Separar responsabilidades em QuestionService - Melhora manutenibilidade
Reduzir complexidade de process_questions - Facilita compreensÃ£o
Implementar pattern Unit of Work - Garante consistÃªncia transacional
Melhorar docstrings conforme PEP 257 - Facilita manutenÃ§Ã£o
Baixa Prioridade (DesejÃ¡vel)
Padronizar formataÃ§Ã£o com Black/isort - ConsistÃªncia visual
Remover cÃ³digo comentado - Limpeza
Extrair magic numbers para constantes - Clareza
Implementar batch processing - OtimizaÃ§Ã£o de performance
ğŸš€ RecomendaÃ§Ãµes Finais
Pontos Positivos
âœ… ImplementaÃ§Ã£o funcional de detecÃ§Ã£o de duplicatas
âœ… Uso de type hints consistente
âœ… SeparaÃ§Ã£o em camadas bem definida
âœ… Logging estruturado para rastreabilidade

Ãreas de Melhoria CrÃ­ticas
Cobertura de Testes: Aumentar para pelo menos 80%, incluindo casos de erro
ValidaÃ§Ã£o de Dados: Implementar validaÃ§Ã£o robusta em todas as camadas
SeparaÃ§Ã£o de Responsabilidades: Refatorar classes com mÃºltiplas responsabilidades
Performance: Implementar busca em lote e garantir Ã­ndices apropriados
PrÃ³ximos Passos Sugeridos
Criar issues no GitHub para cada categoria de problema
Priorizar refatoraÃ§Ãµes de alta prioridade
Estabelecer pipeline de CI/CD com verificaÃ§Ã£o de:
Cobertura mÃ­nima de testes (80%)
Linting (flake8, pylint)
FormataÃ§Ã£o (black, isort)
Type checking (mypy)
Implementar code review obrigatÃ³rio antes de merge
Documentar padrÃµes de cÃ³digo no projeto
